from nltk.tokenize import word_tokenize
sentence = input()
print(word_tokenize(sentence))
